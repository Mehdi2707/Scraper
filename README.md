# ü§ñ Scraper d'Alertes Multi-Sites (Ticketmaster & LevelsAuto)

Ce projet est une solution de surveillance automatis√©e con√ßue pour scruter plusieurs sites web √† la recherche de changements (nouvelles places, nouveaux v√©hicules, etc.) et envoyer des notifications par e-mail lorsqu'une alerte enregistr√©e en base de donn√©es est d√©clench√©e. Il est construit sur une architecture modulaire, ce qui facilite l'ajout de nouveaux sites de scraping.

## üöÄ Fonctionnalit√©s Cl√©s

* **Scraping Multi-Site :** Prise en charge initiale de **Ticketmaster** (surveillance de billets/cat√©gories) et **LevelsAuto** (surveillance de nouveaux v√©hicules).
* **Architecture Modulaire :** Les logiques de scraping sont isol√©es dans des fichiers d√©di√©s (`utils/levelsAuto`, `utils/ticketMaster`), permettant une extensibilit√© facile.
* **Surveillance Permanente :** Le programme tourne en boucle, ex√©cutant les alertes de la base de donn√©es √† intervalles r√©guliers (20 secondes par d√©faut).
* **D√©tection Intelligente :**
    * **Ticketmaster :** D√©tection de la disponibilit√© d'une cat√©gorie sp√©cifique ou g√©n√©rique.
    * **LevelsAuto :** D√©tection de **nouveaux produits** par comparaison de contenu HTML stock√© en DB, garantissant que seules les annonces r√©ellement nouvelles d√©clenchent une notification.
* **Syst√®me d'Alertes Centralis√© :** Les alertes sont g√©r√©es via une base de donn√©es (acc√®s via `database.js`).
* **Notifications par E-mail :** Envoi d'e-mails pour chaque √©v√©nement d√©tect√©.
* **Anti-D√©tection (Stealth) :** Utilisation de `puppeteer-extra` et du plugin `puppeteer-extra-plugin-stealth` pour minimiser le risque de blocage.

---

## üõ†Ô∏è Installation

### Pr√©requis

* **Node.js** (v18+)
* **Une base de donn√©es** (MySQL, MariaDB, etc.)
* **Un compte e-mail** et ses identifiants SMTP (pour l'envoi des notifications).

### √âtapes

1.  **Cloner le d√©p√¥t** :
    ```bash
    git clone [URL_DE_VOTRE_DEPOT]
    cd [NOM_DU_DOSSIER]
    ```

2.  **Installer les d√©pendances** :
    ```bash
    npm install
    # Installation de JSDOM est n√©cessaire pour l'analyse HTML du scraper LevelsAuto
    npm install jsdom
    ```

3.  **Configuration de l'environnement (`.env`)** :
    Cr√©ez un fichier `.env` √† la racine du projet et configurez les acc√®s √† la DB et au service d'e-mail.

    ```env
    # --- Configuration Base de Donn√©es ---
    DB_HOST=localhost
    DB_USER=root
    DB_PASSWORD=votre_mot_de_passe
    DB_NAME=votre_base_de_donnees

    # --- Configuration E-mail (SMTP) ---
    MAIL_SERVICE=gmail # ou outlook, sendgrid, etc.
    MAIL_ADDRESS=votre_email@example.com
    MAIL_PASSWORD=votre_mot_de_passe_ou_cle_api
    ```

4.  **Configuration de la Base de Donn√©es** :

    Assurez-vous que votre table `alerts` contient au moins les colonnes suivantes :

    | Colonne | Type | R√¥le |
    | :--- | :--- | :--- |
    | **`id`** | INT (PK) | Identifiant de l'alerte. |
    | **`link`** | VARCHAR | URL cible du scraping. |
    | **`email`** | VARCHAR | E-mail du destinataire. |
    | **`categorie`** | VARCHAR | Cat√©gorie/mot-cl√© sp√©cifique. |
    | **`is_closed`** | BOOLEAN | `1` si l'alerte est ferm√©e. |
    | **`is_accessible`**| BOOLEAN | **Discriminateur de Scraper :** `0` pour Ticketmaster, `1` pour LevelsAuto. |
    | **`html`** | LONGTEXT | Stocke le HTML pour comparaison (utilis√© par LevelsAuto). |
    | **`close_alert`** | BOOLEAN | Indique si l'alerte doit √™tre ferm√©e apr√®s la premi√®re notification. |

---

## ‚öôÔ∏è Utilisation

Pour lancer le service de scraping en boucle :

```bash
node start-scrap.js